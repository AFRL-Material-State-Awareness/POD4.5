<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Nonlinear Least-Squares Fitting</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for lsqnonlin {pracma}"><tr><td>lsqnonlin {pracma}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>
Nonlinear Least-Squares Fitting
</h2>

<h3>Description</h3>

<p><code>lsqnonlin</code> solves nonlinear least-squares problems, including
nonlinear data-fitting problems, through the Levenberg-Marquardt approach.
</p>
<p><code>lsqnonneg</code> solve nonnegative least-squares constraints problem.
</p>


<h3>Usage</h3>

<pre>
lsqnonlin(fun, x0, options = list(), ...)
lsqnonneg(C, d)

lsqsep(flist, p0, xdata, ydata, const = TRUE)
lsqcurvefit(fun, p0, xdata, ydata)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>fun</code></td>
<td>
<p>User-defined, vector-valued function.</p>
</td></tr>
<tr valign="top"><td><code>x0</code></td>
<td>
<p>starting point.</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>additional parameters passed to the function.</p>
</td></tr>
<tr valign="top"><td><code>options</code></td>
<td>
<p>list of options, for details see below.</p>
</td></tr>
<tr valign="top"><td><code>C, d</code></td>
<td>
<p>matrix and vector such that <code>C x - d</code> will be
minimized with <code>x &gt;= 0</code>.</p>
</td></tr>
<tr valign="top"><td><code>flist</code></td>
<td>
<p>list of (nonlinear) functions, depending on one extra parameter.</p>
</td></tr>
<tr valign="top"><td><code>p0</code></td>
<td>
<p>starting parameters.</p>
</td></tr>
<tr valign="top"><td><code>xdata, ydata</code></td>
<td>
<p>data points to be fitted.</p>
</td></tr>
<tr valign="top"><td><code>const</code></td>
<td>
<p>logical; shall a constant term be included.</p>
</td></tr>
</table>


<h3>Details</h3>

<p><code>lsqnonlin</code> computes the sum-of-squares of the vector-valued function
<code>fun</code>, that is if <i>f(x) = (f_1(x), &hellip; ,f_n(x))</i> then
</p>
<p style="text-align: center;"><i>min || f(x) ||_2^2 = min(f_1(x)^2 + &hellip; + f_n(x)^2)</i></p>

<p>will be minimized.
</p>
<p><code>x=lsqnonlin(fun,x0)</code> starts at point <code>x0</code> and finds a minimum
of the sum of squares of the functions described in fun. <code>fun</code> shall
return a vector of values and not the sum of squares of the values.
(The algorithm implicitly sums and squares fun(x).)
</p>
<p><code>options</code> is a list with the following components and defaults:
</p>

<ul>
<li> <p><code>tau</code>: used as starting value for Marquardt parameter.
</p>
</li>
<li> <p><code>tolx</code>: stopping parameter for step length.
</p>
</li>
<li> <p><code>tolg</code>: stopping parameter for gradient.
</p>
</li>
<li> <p><code>maxeval</code> the maximum number of function evaluations.
</p>
</li></ul>

<p>Typical values for <code>tau</code> are from <code>1e-6...1e-3...1</code> with small
values for good starting points and larger values for not so good or known
bad starting points.
</p>
<p><code>lsqnonneg</code> solves the linear least-squares problem <code>C x - d</code>,
<code>x</code> nonnegative, treating it through an active-set approach..
</p>
<p><code>lsqsep</code> solves the separable least-squares fitting problem
</p>
<p><code>y = a0 + a1*f1(b1, x) + ... + an*fn(bn, x)</code>
</p>
<p>where <code>fi</code> are nonlinear functions each depending on a single extra
paramater <code>bi</code>, and <code>ai</code> are additional linear parameters that
can be separated out to solve a nonlinear problem in the <code>bi</code> alone.
</p>
<p><code>lsqcurvefit</code> is simply an application of <code>lsqnonlin</code> to fitting
data points. <code>fun(p, x)</code> must be a function of two groups of variables
such that <code>p</code> will be varied to minimize the least squares sum, see
the example below.
</p>


<h3>Value</h3>

<p><code>lsqnonlin</code> returns a list with the following elements:
</p>

<ul>
<li> <p><code>x</code>: the point with least sum of squares value.
</p>
</li>
<li> <p><code>ssq</code>: the sum of squares.
</p>
</li>
<li> <p><code>ng</code>: norm of last gradient.
</p>
</li>
<li> <p><code>nh</code>: norm of last step used.
</p>
</li>
<li> <p><code>mu</code>: damping parameter of Levenberg-Marquardt.
</p>
</li>
<li> <p><code>neval</code>: number of function evaluations.
</p>
</li>
<li> <p><code>errno</code>: error number, corresponds to error message.
</p>
</li>
<li> <p><code>errmess</code>: error message, i.e. reason for stopping.
</p>
</li></ul>

<p><code>lsqnonneg</code> returns a list of <code>x</code> the non-negative solition, and
<code>resid.norm</code> the norm of the residual.
</p>
<p><code>lsqsep</code> will return the coefficients sparately, <code>a0</code> for the
constant term (being 0 if <code>const=FALSE</code>) and the vectors <code>a</code> and
<code>b</code> for the linear and nonlinear terms, respectively.
</p>


<h3>Note</h3>

<p>The refined approach, Fletcher's version of the Levenberg-Marquardt
algorithm, may be added at a later time; see the references.
</p>


<h3>References</h3>

<p>Madsen, K., and H. B.Nielsen (2010). Introduction to Optimization and
Data Fitting. Technical University of Denmark, Intitute of Computer
Science and Mathematical Modelling.
</p>
<p>Lawson, C.L., and R.J. Hanson (1974). Solving Least-Squares Problems.
Prentice-Hall, Chapter 23, p. 161.
</p>
<p>Fletcher, R., (1971). A Modified Marquardt Subroutine for Nonlinear Least
Squares. Report AERE-R 6799, Harwell.
</p>


<h3>See Also</h3>

<p><code><a href="../../stats/html/nlm.html">nlm</a></code>, <code><a href="../../stats/html/nls.html">nls</a></code>
</p>


<h3>Examples</h3>

<pre>
##  Rosenberg function as least-squares problem
x0  &lt;- c(0, 0)
fun &lt;- function(x) c(10*(x[2]-x[1]^2), 1-x[1])
lsqnonlin(fun, x0)

##  Example from R-help
y &lt;- c(5.5199668,  1.5234525,  3.3557000,  6.7211704,  7.4237955,  1.9703127,
       4.3939336, -1.4380091,  3.2650180,  3.5760906,  0.2947972,  1.0569417)
x &lt;- c(1,   0,   0,   4,   3,   5,  12,  10,  12, 100, 100, 100)
# Define target function as difference
f &lt;- function(b)
     b[1] * (exp((b[2] - x)/b[3]) * (1/b[3]))/(1 + exp((b[2] - x)/b[3]))^2 - y
x0 &lt;- c(21.16322, 8.83669, 2.957765)
lsqnonlin(f, x0)        # ssq 50.50144 at c(36.133144, 2.572373, 1.079811)

# nls() will break down
# nls(Y ~ a*(exp((b-X)/c)*(1/c))/(1 + exp((b-X)/c))^2,
#     start=list(a=21.16322, b=8.83669, c=2.957765), algorithm = "plinear")
# Error: step factor 0.000488281 reduced below 'minFactor' of 0.000976563

##  Example: Hougon function
x1 &lt;- c(470, 285, 470, 470, 470, 100, 100, 470, 100, 100, 100, 285, 285)
x2 &lt;- c(300,  80, 300,  80,  80, 190,  80, 190, 300, 300,  80, 300, 190)
x3 &lt;- c( 10,  10, 120, 120,  10,  10,  65,  65,  54, 120, 120,  10, 120)
rate &lt;- c(8.55,  3.79, 4.82, 0.02,  2.75, 14.39, 2.54,
          4.35, 13.00, 8.50, 0.05, 11.32,  3.13)
fun &lt;- function(b)
        (b[1]*x2 - x3/b[5])/(1 + b[2]*x1 + b[3]*x2 + b[4]*x3) - rate
lsqnonlin(fun, rep(1, 5))
# $x    [1.25258502 0.06277577 0.04004772 0.11241472 1.19137819]
# $ssq  0.298901

##  Example for lsqnonneg()
C1 &lt;- matrix( c(0.1210, 0.2319, 0.4398, 0.9342, 0.1370,
                0.4508, 0.2393, 0.3400, 0.2644, 0.8188,
                0.7159, 0.0498, 0.3142, 0.1603, 0.4302,
                0.8928, 0.0784, 0.3651, 0.8729, 0.8903,
                0.2731, 0.6408, 0.3932, 0.2379, 0.7349,
                0.2548, 0.1909, 0.5915, 0.6458, 0.6873,
                0.8656, 0.8439, 0.1197, 0.9669, 0.3461,
                0.2324, 0.1739, 0.0381, 0.6649, 0.1660,
                0.8049, 0.1708, 0.4586, 0.8704, 0.1556,
                0.9084, 0.9943, 0.8699, 0.0099, 0.1911), ncol = 5, byrow = TRUE)
C2 &lt;- C1 - 0.5
d &lt;- c(0.4225, 0.8560, 0.4902, 0.8159, 0.4608,
       0.4574, 0.4507, 0.4122, 0.9016, 0.0056)
( sol &lt;- lsqnonneg(C1, d) )     #-&gt; resid.norm   0.3694372
( sol &lt;- lsqnonneg(C2, d) )     #-&gt; $resid.norm  2.863979

##  Example for lsqcurvefit()
#   Lanczos1 data (artificial data)
#   f(x) = 0.0951*exp(-x) + 0.8607*exp(-3*x) + 1.5576*exp(-5*x)
x &lt;- linspace(0, 1.15, 24)
y &lt;- c(2.51340000, 2.04433337, 1.66840444, 1.36641802, 1.12323249, 0.92688972,
       0.76793386, 0.63887755, 0.53378353, 0.44793636, 0.37758479, 0.31973932,
       0.27201308, 0.23249655, 0.19965895, 0.17227041, 0.14934057, 0.13007002,
       0.11381193, 0.10004156, 0.08833209, 0.07833544, 0.06976694, 0.06239313)

p0 &lt;- c(1.2, 0.3, 5.6, 5.5, 6.5, 7.6)
fp &lt;- function(p, x) p[1]*exp(-p[2]*x) + p[3]*exp(-p[4]*x) + p[5]*exp(-p[6]*x)
lsqcurvefit(fp, p0, x, y)

##  Example for lsqsep()
f &lt;- function(x) 0.5 + x^-0.5 + exp(-0.5*x)
set.seed(8237); n &lt;- 15
x &lt;- sort(0.5 + 9*runif(n))
y &lt;- f(x)                       #y &lt;- f(x) + 0.01*rnorm(n)

m &lt;- 2
f1 &lt;- function(b, x) x^b
f2 &lt;- function(b, x) exp(b*x)
flist &lt;- list(f1, f2)
start &lt;- c(-0.25, -0.75)

sol &lt;- lsqsep(flist, start, x, y, const = TRUE)
a0 &lt;- sol$a0; a &lt;- sol$a; b &lt;- sol$b
fsol &lt;- function(x) a0 + a[1]*f1(b[1], x) + a[2]*f2(b[2], x)

## Not run: 
    ezplot(f, 0.5, 9.5, col = "gray")
    points(x, y, col = "blue")
    xs &lt;- linspace(0.5, 9.5, 51)
    ys &lt;- fsol(xs)
    lines(xs, ys, col = "red")

## End(Not run)
</pre>

<hr /><div style="text-align: center;">[Package <em>pracma</em> version 2.3.8 <a href="00Index.html">Index</a>]</div>
</body></html>
