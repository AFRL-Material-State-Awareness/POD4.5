<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Generate Bates and Watts D Matrix</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body>

<table width="100%" summary="page for genD {numDeriv}"><tr><td>genD {numDeriv}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Generate Bates and Watts D Matrix</h2>

<h3>Description</h3>

<p>Generate a matrix of function derivative information.</p>


<h3>Usage</h3>

<pre>
    genD(func, x, method="Richardson",
                   method.args=list(), ...)
    ## Default S3 method:
genD(func, x, method="Richardson",
      method.args=list(), ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>func</code></td>
<td>
<p>a function for which the first (vector) argument 
is used as a parameter vector.</p>
</td></tr>
<tr valign="top"><td><code>x</code></td>
<td>
<p>The parameter vector first argument to <code>func</code>.</p>
</td></tr>
<tr valign="top"><td><code>method</code></td>
<td>
<p>one of <code>"Richardson"</code> or <code>"simple"</code> indicating 
the method to use for the aproximation.</p>
</td></tr>
<tr valign="top"><td><code>method.args</code></td>
<td>
<p>arguments passed to method.  See <code><a href="grad.html">grad</a></code>. 
(Arguments not specified remain with their default values.)</p>
</td></tr>
<tr valign="top"><td><code>...</code></td>
<td>
<p>any additional arguments passed to <code>func</code>.
WARNING: None of these should have names matching other arguments of this function.</p>
</td></tr>
</table>


<h3>Details</h3>

<p>The derivatives are calculated numerically using Richardson improvement.
Methods &quot;simple&quot; and &quot;complex&quot; are not supported in this function.
The &quot;Richardson&quot; method calculates a numerical approximation of the first 
and second derivatives of <code>func</code> at the point <code>x</code>. 
For a scalar valued function these are the gradient vector and 
Hessian matrix. (See <code><a href="grad.html">grad</a></code> and <code><a href="hessian.html">hessian</a></code>.)
For a vector valued function the first derivative is the Jacobian matrix 
(see <code><a href="jacobian.html">jacobian</a></code>). 
For the Richardson method 
<code>method.args=list(eps=1e-4, d=0.0001, zero.tol=sqrt(.Machine$double.eps/7e-7), 
   r=4, v=2)</code> is set as the default.
See <code><a href="grad.html">grad</a></code>
for more details on the Richardson's extrapolation parameters. 
</p>
<p>A simple approximation to the first order derivative with respect 
to <i>x_i</i> is 
</p>
<p style="text-align: center;"><i>
 	 f'_{i}(x) = &lt;f(x_{1},&hellip;,x_{i}+d,&hellip;,x_{n}) -
               f(x_{1},&hellip;,x_{i}-d,&hellip;,x_{n})&gt;/(2*d)</i></p>

<p>A simple approximation to the second order derivative with respect 
to <i>x_i</i> is 
</p>
<p style="text-align: center;"><i>
	f''_{i}(x) = &lt;f(x_{1},&hellip;,x_{i}+d,&hellip;,x_{n}) -
                   2 *f(x_{1},&hellip;,x_{n}) +
                    f(x_{1},&hellip;,x_{i}-d,&hellip;,x_{n})&gt;/(d^2) </i></p>
	    
<p>The second order derivative with respect to <i>x_i, x_j</i> is 
</p>
<p style="text-align: center;"><i>
        f''_{i,j}(x) = &lt;f(x_{1},&hellip;,x_{i}+d,&hellip;,x_{j}+d,&hellip;,x_{n}) -
                    2 *f(x_{1},&hellip;,x_{n}) + </i></p>

<p style="text-align: center;"><i>
        f(x_{1},&hellip;,x_{i}-d,&hellip;,x_{j}-d,&hellip;,x_{n})&gt;/(2*d^2) -
		      (f''_{i}(x) + f''_{j}(x))/2 </i></p>

<p>Richardson's extrapolation is based on these formula with the <code>d</code> 
being reduced in the extrapolation iterations. In the code, <code>d</code> is
scaled to accommodate parameters of different magnitudes. 
</p>
<p><code>genD</code> does <code>1 + r (N^2 + N)</code> evaluations of the function
<code>f</code>, where <code>N</code> is the length of <code>x</code>.
</p>


<h3>Value</h3>

<p>A list with elements as follows:
<code>D</code> is a matrix of first and second order partial
derivatives organized in the same manner as Bates and 
Watts, the number of rows is equal to the length of the result of
<code>func</code>, the first p columns are the Jacobian, and the 
next p(p+1)/2 columns are the lower triangle of the second derivative
(which is the Hessian for a scalar valued <code>func</code>).
<code>p</code> is the length of <code>x</code> (dimension of the parameter space).
<code>f0</code> is the function value at the point where the matrix <code>D</code> 
was calculated. 
The  <code>genD</code> arguments <code>func</code>, <code>x</code>, <code>d</code>, <code>method</code>,
and  <code>method.args</code> also are returned in the list.
</p>


<h3>References</h3>

 
<p>Linfield, G.R. and Penny, J.E.T. (1989) &quot;Microcomputers in Numerical Analysis.&quot;
Halsted Press.
</p>
<p>Bates, D.M. &amp; Watts, D. (1980), &quot;Relative Curvature Measures of Nonlinearity.&quot;
J. Royal Statistics Soc. series B, 42:1-25
</p>
<p>Bates, D.M. and Watts, D. (1988) &quot;Non-linear Regression Analysis and Its Applications.&quot;
Wiley.
</p>


<h3>See Also</h3>

<p><code><a href="hessian.html">hessian</a></code>, 
<code><a href="grad.html">grad</a></code>
</p>


<h3>Examples</h3>

<pre>
    func &lt;- function(x){c(x[1], x[1], x[2]^2)}
    z &lt;- genD(func, c(2,2,5))
</pre>

<hr /><div style="text-align: center;">[Package <em>numDeriv</em> version 2016.8-1.1 <a href="00Index.html">Index</a>]</div>
</body></html>
